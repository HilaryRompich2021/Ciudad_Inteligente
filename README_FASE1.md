# Fase 1: Microservicio Ingestor y Kafka - Ciudad Inteligente ‚úÖ COMPLETADO

## üéØ ¬øQu√© se implement√≥?

Se desarroll√≥ un sistema distribuido para la **ingesta de eventos en tiempo real** para una ciudad inteligente, utilizando **microservicios**, **Apache Kafka** y **Docker**. El sistema permite recibir eventos can√≥nicos v√≠a API REST, validarlos contra un esquema oficial estricto y publicarlos en Kafka para su procesamiento posterior.

### ‚úÖ **Estado actual: FUNCIONANDO**
- üü¢ **Microservicio Ingestor**: Operativo en puerto 8080
- üü¢ **Kafka**: Topics auto-creados y mensajes public√°ndose correctamente
- üü¢ **Validaci√≥n JSON Schema**: Esquema can√≥nico v1.0 implementado seg√∫n gu√≠a oficial
- üü¢ **Docker Compose**: Infraestructura completa orquestada
- üü¢ **Kafka UI**: Interfaz web disponible en puerto 8081 para monitoreo

---

## üèóÔ∏è Arquitectura Implementada

```
[Cliente HTTP/Postman/Insomnia] 
           ‚Üì POST /events (JSON can√≥nico)
    [Microservicio Ingestor:8080]
           ‚Üì Validaci√≥n + Enriquecimiento
           ‚Üì Kafka Producer
         [Apache Kafka]
           ‚Üì Topic: t01.events.standardized
        [Kafka UI:8081] (Monitoreo)
```

### üõ†Ô∏è **Stack tecnol√≥gico:**
- **Backend**: Java 17 + Spring Boot 3.5.5
- **Broker**: Apache Kafka 3.7 + Zookeeper 3.8
- **Validaci√≥n**: JSON Schema 2020-12 con networknt/json-schema-validator
- **Contenedores**: Docker + Docker Compose
- **Base de datos**: PostgreSQL 16 (preparado para siguientes fases)
- **Cache**: Redis 7 (preparado para correlaci√≥n de eventos)
- **Monitoreo**: Kafka UI

---

## üìã Proceso Paso a Paso

### 1. **Arranque de la infraestructura**
```bash
# Desde el directorio platform/
docker-compose up --build -d
```
- ‚úÖ Kafka + Zookeeper: Broker de mensajes
- ‚úÖ PostgreSQL: Base de datos (para futuras fases)
- ‚úÖ Redis: Cache (para correlaci√≥n de eventos)
- ‚úÖ Kafka UI: Interfaz web de monitoreo
- ‚úÖ **Microservicio Ingestor**: Punto de entrada de eventos

### 2. **Creaci√≥n autom√°tica de topics**
Los topics se crean **autom√°ticamente** al iniciar el microservicio:
- üì® `t01.events.standardized`: Eventos can√≥nicos validados
- üö® `t01.correlated.alerts`: Alertas correlacionadas (para Fase 2)

### 3. **Recepci√≥n y validaci√≥n de eventos**

El microservicio ingestor expone **4 endpoints principales**:

#### **üìã Endpoints disponibles:**
- üü¢ `POST /events` - Procesar un evento individual
- üü¢ `POST /events/bulk` - Procesar m√∫ltiples eventos en lote
- üü¢ `GET /health` - Estado del servicio y conectividad
- üü¢ `GET /schema` - Obtener el esquema can√≥nico JSON

---

## üìù **Campos del Evento Can√≥nico**

### **‚úÖ Campos OBLIGATORIOS** (seg√∫n esquema JSON):
- `event_version` *(string)*: Siempre "1.0"
- `event_type` *(enum)*: panic.button | sensor.lpr | sensor.speed | sensor.acoustic | citizen.report
- `event_id` *(string)*: Identificador √∫nico del evento
- `producer` *(string)*: Sistema que genera el evento
- `source` *(enum)*: Solo "simulated" por ahora
- `timestamp` *(datetime)*: ISO 8601 (se genera autom√°ticamente si no se env√≠a)
- `partition_key` *(string)*: Clave para particionado de Kafka
- `geo` *(object)*: **Todos los campos son obligatorios** (`zone`, `lat`, `lon`)
  - `zone` *(string)*: Identificador de zona (ej: "downtown", "north", "highway-101")
  - `lat` *(number)*: Latitud (-90 a 90)
  - `lon` *(number)*: Longitud (-180 a 180)
- `severity` *(enum)*: info | warning | critical
- `payload` *(object)*: Datos espec√≠ficos del evento (estructura libre)
  - **Nota**: Actualmente acepta cualquier estructura JSON v√°lida
  - **Pr√≥xima mejora**: Validaciones espec√≠ficas por tipo de evento (ver secci√≥n "Mejoras futuras")

### **‚ö™ Campos OPCIONALES** (se generan autom√°ticamente si no se env√≠an):
- `correlation_id` *(string)*: UUID para correlaci√≥n de eventos
- `trace_id` *(string)*: UUID para trazabilidad

---

## üîÆ **Mejoras futuras planeadas**

### **Validaciones espec√≠ficas de payload por tipo de evento:**

Estas validaciones est√°n planificadas para implementarse despu√©s de completar el correlador:

#### **üö® panic.button**
```json
"payload": {
  "tipo_de_alerta": "panico | emergencia | incendio",  // enum obligatorio
  "user_context": "movil | quiosco | web",             // enum obligatorio
  "device_id": "string",                               // opcional
  "battery_level": "number (0-100)"                    // opcional
}
```

#### **üöó sensor.lpr**
```json
"payload": {
  "placa_vehicular": "string (formato espec√≠fico)",    // obligatorio
  "ubicacion_sensor": "string",                        // obligatorio
  "confidence": "number (0-1)",                        // opcional
  "vehicle_type": "sedan | truck | motorcycle | ..."  // opcional
}
```

#### **üèÉ sensor.speed**
```json
"payload": {
  "velocidad_detectada": "number (> 0)",               // obligatorio
  "direccion": "NORTE | SUR | ESTE | OESTE",          // enum obligatorio
  "speed_limit": "number",                             // opcional
  "vehicle_type": "string"                             // opcional
}
```

#### **üîä sensor.acoustic**
```json
"payload": {
  "tipo_sonido_detectado": "disparo | explosion | vidrio_roto | normal", // enum obligatorio
  "probabilidad_evento_critico": "number (0-1)",      // obligatorio
  "decibel_level": "number",                           // opcional
  "duration_ms": "number"                              // opcional
}
```

#### **üë§ citizen.report**
```json
"payload": {
  "tipo_evento": "accidente | incendio | altercado | vandalismo", // enum obligatorio
  "origen": "usuario | app | punto_fisico",           // enum obligatorio
  "description": "string",                             // opcional
  "citizen_id": "string",                              // opcional
  "attachments": "array"                               // opcional
}
```

### **Beneficios de implementar estas validaciones:**
- ‚úÖ **Datos m√°s consistentes**: Garantiza que cada tipo de evento tenga la estructura esperada
- ‚úÖ **Mejor correlaci√≥n**: El correlador puede confiar en la estructura espec√≠fica de cada payload
- ‚úÖ **Detecci√≥n temprana de errores**: Errores de estructura se detectan en el ingestor, no en el correlador
- ‚úÖ **API m√°s robusta**: Clientes reciben retroalimentaci√≥n espec√≠fica sobre errores en el payload

---

## üß™ **Ejemplos de uso de endpoints**

### **1. POST /events - Evento individual con TODOS los campos**

```bash
curl -X POST http://localhost:8080/events \
  -H "Content-Type: application/json" \
  -d '{
    "event_version": "1.0",
    "event_type": "panic.button",
    "event_id": "evt-2025-09-10-001",
    "producer": "mobile-app",
    "source": "simulated",
    "correlation_id": "corr-2025-09-10-001",
    "trace_id": "trace-2025-09-10-001",
    "timestamp": "2025-09-10T15:30:00Z",
    "partition_key": "zone-downtown",
    "geo": {
      "zone": "downtown",
      "lat": 19.4326,
      "lon": -99.1332
    },
    "severity": "critical",
    "payload": {
      "device_id": "panic-btn-001",
      "user_id": "citizen-1234",
      "battery_level": 85
    }
  }
```

### **2. POST /events - Evento con AUTOCOMPLETADO (campos m√≠nimos)**

```bash
curl -X POST http://localhost:8080/events \
  -H "Content-Type: application/json" \
  -d '{
    "event_version": "1.0",
    "event_type": "sensor.lpr",
    "event_id": "evt-2025-09-10-002",
    "producer": "camera-system",
    "source": "simulated",
    "partition_key": "zone-north",
    "geo": {
      "zone": "north",
      "lat": 19.4500,
      "lon": -99.1300
    },
    "severity": "info",
    "payload": {
      "plate_number": "ABC123",
      "confidence": 0.98
    }
  }'
```
> **‚ö° El microservicio autom√°ticamente genera:** `timestamp`, `correlation_id`, `trace_id`

## üìç **Coordenadas de referencia por zona:**

Para facilitar las pruebas, aqu√≠ tienes coordenadas de ejemplo para diferentes zonas:

- **downtown**: `lat: 19.4326, lon: -99.1332` (Centro hist√≥rico)
- **north**: `lat: 19.4500, lon: -99.1300` (Zona Norte)
- **south**: `lat: 19.4100, lon: -99.1400` (Zona Sur)
- **east**: `lat: 19.4300, lon: -99.1200` (Zona Este)
- **west**: `lat: 19.4300, lon: -99.1500` (Zona Oeste)
- **highway-101**: `lat: 19.3852, lon: -99.1781` (Carretera principal)
- **zone-test**: `lat: 19.4200, lon: -99.1350` (Zona de pruebas)

### **3. POST /events/bulk - M√∫ltiples eventos con AUTOCOMPLETADO**

```bash
curl -X POST http://localhost:8080/events/bulk \
  -H "Content-Type: application/json" \
  -d '[
    {
      "event_version": "1.0",
      "event_type": "sensor.speed",
      "event_id": "evt-2025-09-10-003",
      "producer": "speed-sensor",
      "source": "simulated",
      "partition_key": "highway-101",
      "geo": {
        "zone": "highway-101",
        "lat": 19.3852,
        "lon": -99.1781
      },
      "severity": "warning",
      "payload": {
        "speed": 135.5,
        "speed_limit": 80,
        "vehicle_type": "motorcycle"
      }
    },
    {
      "event_version": "1.0",
      "event_type": "citizen.report",
      "event_id": "evt-2025-09-10-004",
      "producer": "citizen-app",
      "source": "simulated",
      "partition_key": "zone-south",
      "geo": {
        "zone": "south",
        "lat": 19.4100,
        "lon": -99.1400
      },
      "severity": "info",
      "payload": {
        "report_type": "graffiti",
        "description": "Vandalism on public wall"
      }
    }
  ]'
```

**üí° Respuesta de /events/bulk:**
```json
{
  "total": 2,
  "successful": 2,
  "failed": 0,
  "successful_events": ["evt-2025-09-10-003", "evt-2025-09-10-004"],
  "failed_events": [],
  "timestamp": "2025-09-10T15:35:00Z"
}
```

### **4. GET /health - Estado del servicio**

```bash
curl -X GET http://localhost:8080/health
```

**Respuesta esperada:**
```json
{
  "status": "UP",
  "kafka": "connected",
  "validator": "ready",
  "timestamp": "2025-09-10T15:30:45Z",
  "service": "ingestor",
  "version": "1.0",
  "details": {
    "topic": "t01.events.standardized",
    "schema_version": "1.0"
  }
}
```

### **5. GET /schema - Esquema can√≥nico**

```bash
curl -X GET http://localhost:8080/schema
```

Devuelve el esquema JSON completo usado para validaci√≥n.

---

## üö® **Casos de error comunes**

### **‚ùå Campo obligatorio faltante:**
```json
{
  "event_version": "1.0",
  "event_type": "panic.button"
  // Faltan: event_id, producer, source, partition_key, geo, severity, payload
}
```
**Respuesta:** `400 Bad Request` con detalles de validaci√≥n

### **‚ùå Tipo de evento inv√°lido:**
```json
{
  "event_type": "invalid.type"  // Solo se permiten los 5 tipos definidos
}
```

### **‚ùå Geo sin zone (campo obligatorio):**
```json
{
  "geo": {
    "lat": 19.4326,
    "lon": -99.1332
    // Falta: "zone" (obligatorio)
  }
}
```

### **‚ùå JSON mal formado:**
```json
{
  "event_id": "test"
  "event_type": "panic.button"  // Falta coma
}
```

### 4. **Validaci√≥n estricta y enriquecimiento**
- ‚úÖ **JSON Schema v1.0**: Validaci√≥n contra esquema oficial del proyecto
- ‚úÖ **Campos obligatorios**: `event_version`, `event_type`, `event_id`, `producer`, `source`, `timestamp`, `partition_key`, `geo` (con `zone`, `lat`, `lon`), `severity`, `payload`
- ‚úÖ **Enriquecimiento autom√°tico**: Si faltan `timestamp`, `trace_id`, o `correlation_id`, se generan autom√°ticamente con UUID
- ‚úÖ **Snake_case mapping**: Mapeo autom√°tico entre JSON (snake_case) y Java (camelCase)
- ‚úÖ **Procesamiento en lote**: El endpoint `/events/bulk` procesa eventos independientemente (si uno falla, los dem√°s contin√∫an)

#### **Tipos de eventos soportados:**
- `panic.button`: Botones de p√°nico ciudadano
- `sensor.lpr`: C√°maras de reconocimiento de placas
- `sensor.speed`: Sensores de velocidad/movimiento  
- `sensor.acoustic`: Sensores ac√∫sticos/ambientales
- `citizen.report`: Reportes ciudadanos v√≠a app m√≥vil

### 5. **Publicaci√≥n exitosa en Kafka**
- üì® **Topic**: `t01.events.standardized`
- üîë **Key**: `partition_key` (ej: "zone_4") para afinidad de partici√≥n
- ‚úÖ **Confirmaci√≥n**: Logs de publicaci√≥n exitosa
- üëÅÔ∏è **Monitoreo**: Mensajes visibles en Kafka UI (http://localhost:8081)

---

## üß™ ¬øC√≥mo probar el sistema?

### **Paso 1: Arrancar la infraestructura**
```bash
cd platform/
docker-compose up --build -d
docker ps  # Verificar que todos los contenedores est√©n UP
```

### **Paso 2: Probar los endpoints**

#### **Opci√≥n A: Evento individual b√°sico**
```bash
curl -X POST http://localhost:8080/events \
  -H "Content-Type: application/json" \
  -d '{
    "event_version": "1.0",
    "event_type": "panic.button",
    "event_id": "test-001",
    "producer": "test-client",
    "source": "simulated",
    "partition_key": "zone-test",
    "geo": { 
      "zone": "downtown",
      "lat": 19.4326,
      "lon": -99.1332
    },
    "severity": "critical",
    "payload": { "test": true }
  }'
```

#### **Opci√≥n B: Lote de eventos**
```bash
curl -X POST http://localhost:8080/events/bulk \
  -H "Content-Type: application/json" \
  -d '[
    {
      "event_version": "1.0",
      "event_type": "panic.button",
      "event_id": "bulk-001",
      "producer": "test",
      "source": "simulated",
      "partition_key": "zone-1",
      "geo": { 
        "zone": "north",
        "lat": 19.4500,
        "lon": -99.1300
      },
      "severity": "critical",
      "payload": { "device": "btn-001" }
    },
    {
      "event_version": "1.0",
      "event_type": "sensor.lpr",
      "event_id": "bulk-002",
      "producer": "test",
      "source": "simulated",
      "partition_key": "zone-2",
      "geo": { 
        "zone": "south",
        "lat": 19.4100,
        "lon": -99.1400
      },
      "severity": "info",
      "payload": { "plate": "ABC123" }
    }
  ]'
```

#### **Opci√≥n C: Verificar estado del servicio**
```bash
curl -X GET http://localhost:8080/health
curl -X GET http://localhost:8080/schema
```

### **Paso 3: Verificar en Kafka UI**
- Abrir: http://localhost:8081
- Ir a Topics ‚Üí `t01.events.standardized`
- Verificar que el mensaje aparezca con la key `zone_4`

### **Respuestas esperadas:**
- ‚úÖ `202 Accepted`: Evento(s) procesado(s) y publicado(s) exitosamente
- ‚úÖ `200 OK`: Para endpoints GET (/health, /schema)
- ‚ùå `400 Bad Request`: Error de validaci√≥n (JSON mal formado, campos faltantes o inv√°lidos)
- ‚ùå `500 Internal Server Error`: Error interno del microservicio

---

## üîß Detalles t√©cnicos de implementaci√≥n

### **Estructura del proyecto:**
```
src/ingestor/
‚îú‚îÄ‚îÄ src/main/java/com/ciudadesinteligentes/ingestor/
‚îÇ   ‚îú‚îÄ‚îÄ IngestorApplication.java           # Main Spring Boot
‚îÇ   ‚îú‚îÄ‚îÄ controller/EventController.java    # REST API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ service/EventService.java          # L√≥gica de negocio
‚îÇ   ‚îú‚îÄ‚îÄ model/CanonicalEvent.java         # Modelo con @JsonProperty
‚îÇ   ‚îú‚îÄ‚îÄ config/KafkaConfig.java           # Auto-creaci√≥n de topics
‚îÇ   ‚îî‚îÄ‚îÄ util/CanonicalEventValidator.java # Validador JSON Schema
‚îî‚îÄ‚îÄ src/main/resources/
    ‚îú‚îÄ‚îÄ application.properties             # Configuraci√≥n Spring
    ‚îî‚îÄ‚îÄ canonical-event-schema.json        # Esquema oficial v1.0
```

### **Configuraciones clave:**

**application.properties:**
```properties
spring.application.name=ingestor
spring.kafka.bootstrap-servers=kafka:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.admin.auto-create=true
app.kafka.topic.events-standardized=t01.events.standardized
```

**Auto-creaci√≥n de topics (KafkaConfig.java):**
```java
@Bean
public NewTopic eventsStandardizedTopic() {
    return TopicBuilder.name("t01.events.standardized")
            .partitions(3)
            .replicas(1)
            .build();
}
```

**Mapeo snake_case ‚Üî camelCase:**
```java
@JsonProperty("event_id")
private String eventId;

@JsonProperty("event_type") 
private String eventType;
// ... etc
```

---

## üöÄ Siguientes pasos (Roadmap)

### **Fase 2: Correlator + Redis (Siguiente prioridad)**
- **Objetivo**: Consumir eventos de Kafka y generar alertas correlacionadas
- **Funcionalidad**: 
  - Stream processor que correlaciona eventos dentro de ventanas de tiempo
  - Reglas inteligentes (ej: panic.button + velocidad alta = posible robo)
  - Cache en Redis para estado transitorio
  - Publicaci√≥n de alertas en `t01.correlated.alerts`

### **Fase 2.5: Validaciones espec√≠ficas de payload (Mejora incremental)**
- **Objetivo**: Agregar validaci√≥n granular para cada tipo de evento
- **Funcionalidad**:
  - Esquemas JSON espec√≠ficos para cada `event_type`
  - Validaci√≥n de enums y formatos espec√≠ficos (placas, direcciones, etc.)
  - Mensajes de error m√°s espec√≠ficos para desarrolladores
  - Retrocompatibilidad con eventos existentes

### **Fase 3: Persistencia y ETL**
- Guardar eventos y alertas en PostgreSQL para an√°lisis hist√≥rico
- ETL batch/streaming desde Kafka a base de datos
- √çndices optimizados para consultas geoespaciales y temporales

### **Fase 4: Observabilidad y Dashboards**
- Integraci√≥n con Prometheus + Grafana
- M√©tricas de rendimiento de microservicios y Kafka
- Dashboards en tiempo real con heatmaps y timelines geoespaciales

### **Fase 5: Simuladores y carga**
- Artillery/JMeter para simulaci√≥n de eventos masivos
- Generadores Python para diferentes tipos de sensores
- Pruebas de stress y benchmarking

### **Fase 6: Escalabilidad**
- Schema Registry para evoluci√≥n de schemas
- Particionado inteligente por zona geogr√°fica
- Auto-scaling de microservicios seg√∫n carga

---

## üîç Troubleshooting y comandos √∫tiles

### **Ver logs del microservicio:**
```bash
docker logs platform_ingestor_1 --tail 50 -f
```

### **Verificar topics creados:**
```bash
docker exec -it platform_kafka_1 kafka-topics.sh --bootstrap-server localhost:9092 --list
```

### **Consumir mensajes directamente:**
```bash
docker exec -it platform_kafka_1 kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic t01.events.standardized \
  --from-beginning
```

### **Estado de contenedores:**
```bash
docker ps
docker-compose logs ingestor  # Solo logs del ingestor
```

### **Reiniciar solo el ingestor:**
```bash
docker-compose restart ingestor
# O con rebuild para cambios de c√≥digo:
docker-compose up --build -d ingestor
```

---

## üí° Lecciones aprendidas y mejores pr√°cticas

1. **Validaci√≥n estricta**: El JSON Schema 2020-12 es fundamental para garantizar consistencia
2. **Auto-creaci√≥n de topics**: Evita pasos manuales y mejora la experiencia de desarrollo
3. **Mapeo expl√≠cito**: `@JsonProperty` es m√°s confiable que configuraci√≥n global de Jackson
4. **Enriquecimiento autom√°tico**: Genera autom√°ticamente campos como `trace_id` si faltan
5. **Monitoreo visual**: Kafka UI es esencial para debugging y verificaci√≥n
6. **Dockerizaci√≥n completa**: La infraestructura dockerizada facilita desarrollo y despliegue
7. **Logs estructurados**: Importantes para debugging en entornos distribuidos

---

## üìö Referencias t√©cnicas
- **JSON Schema oficial**: `src/ingestor/src/main/resources/canonical-event-schema.json`
- **Docker Compose**: `platform/docker-compose.yml`
- **Spring Kafka**: https://spring.io/projects/spring-kafka
---

**‚úÖ Estado**: Fase 1 completamente implementada y funcional  
**üéØ Pr√≥ximo objetivo**: Implementar Correlator para generar alertas inteligentes  
**üë• Equipo**: Listo para demo y continuaci√≥n del desarrollo

**¬°Listo para avanzar a la siguiente fase!**

---

## üõ°Ô∏è Validaci√≥n de eventos: Individual vs Bulk

### 1. Endpoint individual (`POST /events`)
- **Validaci√≥n autom√°tica:** Se usa `@Valid` en el controlador para verificar los campos m√≠nimos obligatorios (por anotaciones como `@NotNull`).
- **Validaci√≥n de esquema:** Adem√°s, el evento se valida contra el esquema JSON can√≥nico en el servicio antes de publicarse en Kafka.
- **Errores personalizados:** Si la validaci√≥n autom√°tica falla, un manejador global (`@ControllerAdvice`) devuelve una respuesta JSON detallada con los errores de validaci√≥n.
- **Enriquecimiento:** Si faltan campos opcionales (`timestamp`, `trace_id`, `correlation_id`), se generan autom√°ticamente.

### 2. Endpoint bulk (`POST /events/bulk`)
- **Validaci√≥n manual:** No se usa `@Valid` en el controlador. La validaci√≥n se realiza manualmente en el servicio, evento por evento, usando el esquema JSON can√≥nico.
- **Procesamiento parcial:** Los eventos v√°lidos se publican en Kafka; los inv√°lidos se reportan en la respuesta con detalles (√≠ndice, eventId, mensaje de error).
- **Respuesta estructurada:** La respuesta incluye el total de eventos, los exitosos, los fallidos y los errores espec√≠ficos de cada evento.

**Ventajas de este enfoque:**
- M√°xima robustez y calidad de datos.
- Respuestas claras y personalizadas para el cliente.
- Permite procesamiento parcial en lote y validaci√≥n estricta en ambos casos.

---
