# Fase 1: Microservicio Ingestor y Kafka - Ciudad Inteligente âœ… COMPLETADO

## ğŸ¯ Â¿QuÃ© se implementÃ³?

Se desarrollÃ³ un sistema distribuido para la **ingesta de eventos en tiempo real** para una ciudad inteligente, utilizando **microservicios**, **Apache Kafka** y **Docker**. El sistema permite recibir eventos canÃ³nicos vÃ­a API REST, validarlos contra un esquema oficial estricto y publicarlos en Kafka para su procesamiento posterior.

### âœ… **Estado actual: FUNCIONANDO**
- ğŸŸ¢ **Microservicio Ingestor**: Operativo en puerto 8080
- ğŸŸ¢ **Kafka**: Topics auto-creados y mensajes publicÃ¡ndose correctamente
- ğŸŸ¢ **ValidaciÃ³n JSON Schema**: Esquema canÃ³nico v1.0 implementado segÃºn guÃ­a oficial
- ğŸŸ¢ **Docker Compose**: Infraestructura completa orquestada
- ğŸŸ¢ **Kafka UI**: Interfaz web disponible en puerto 8081 para monitoreo

---

## ğŸ—ï¸ Arquitectura Implementada

```
[Cliente HTTP/Postman/Insomnia] 
           â†“ POST /events (JSON canÃ³nico)
    [Microservicio Ingestor:8080]
           â†“ ValidaciÃ³n + Enriquecimiento
           â†“ Kafka Producer
         [Apache Kafka]
           â†“ Topic: t01.events.standardized
        [Kafka UI:8081] (Monitoreo)
```

### ğŸ› ï¸ **Stack tecnolÃ³gico:**
- **Backend**: Java 17 + Spring Boot 3.5.5
- **Broker**: Apache Kafka 3.7 + Zookeeper 3.8
- **ValidaciÃ³n**: JSON Schema 2020-12 con networknt/json-schema-validator
- **Contenedores**: Docker + Docker Compose
- **Base de datos**: PostgreSQL 16 (preparado para siguientes fases)
- **Cache**: Redis 7 (preparado para correlaciÃ³n de eventos)
- **Monitoreo**: Kafka UI

---

## ğŸ“‹ Proceso Paso a Paso

### 1. **Arranque de la infraestructura**
```bash
# Desde el directorio platform/
docker-compose up --build -d
```
- âœ… Kafka + Zookeeper: Broker de mensajes
- âœ… PostgreSQL: Base de datos (para futuras fases)
- âœ… Redis: Cache (para correlaciÃ³n de eventos)
- âœ… Kafka UI: Interfaz web de monitoreo
- âœ… **Microservicio Ingestor**: Punto de entrada de eventos

### 2. **CreaciÃ³n automÃ¡tica de topics**
Los topics se crean **automÃ¡ticamente** al iniciar el microservicio:
- ğŸ“¨ `t01.events.standardized`: Eventos canÃ³nicos validados
- ğŸš¨ `t01.correlated.alerts`: Alertas correlacionadas (para Fase 2)

### 3. **RecepciÃ³n y validaciÃ³n de eventos**
**Endpoint principal**: `POST http://localhost:8080/events`

#### **Ejemplo de evento canÃ³nico vÃ¡lido:**
```json
{
  "event_version": "1.0",
  "event_type": "panic.button",
  "event_id": "123e4567-e89b-12d3-a456-426614174000",
  "producer": "artillery",
  "source": "simulated",
  "correlation_id": "123e4567-e89b-12d3-a456-426614174001",
  "trace_id": "123e4567-e89b-12d3-a456-426614174002",
  "timestamp": "2025-09-04T21:00:00Z",
  "partition_key": "zone_4",
  "geo": { "zone": "zone_4", "lat": 14.62, "lon": -90.52 },
  "severity": "critical",
  "payload": {
    "tipo_de_alerta": "panico",
    "identificador_dispositivo": "BTN-001",
    "user_context": "movil"
  }
}
```

#### **Tipos de eventos soportados:**
- `panic.button`: Botones de pÃ¡nico
- `sensor.lpr`: CÃ¡maras de reconocimiento de placas
- `sensor.speed`: Sensores de velocidad/movimiento  
- `sensor.acoustic`: Sensores acÃºsticos/ambientales
- `citizen.report`: Reportes ciudadanos

### 4. **ValidaciÃ³n estricta y enriquecimiento**
- âœ… **JSON Schema v1.0**: ValidaciÃ³n contra esquema oficial del proyecto
- âœ… **Campos obligatorios**: `event_version`, `event_type`, `event_id`, `producer`, `source`, `timestamp`, `partition_key`, `geo`, `severity`, `payload`
- âœ… **Enriquecimiento automÃ¡tico**: Si faltan `timestamp`, `trace_id`, o `correlation_id`, se generan automÃ¡ticamente
- âœ… **Snake_case mapping**: Mapeo automÃ¡tico entre JSON (snake_case) y Java (camelCase)

### 5. **PublicaciÃ³n exitosa en Kafka**
- ğŸ“¨ **Topic**: `t01.events.standardized`
- ğŸ”‘ **Key**: `partition_key` (ej: "zone_4") para afinidad de particiÃ³n
- âœ… **ConfirmaciÃ³n**: Logs de publicaciÃ³n exitosa
- ğŸ‘ï¸ **Monitoreo**: Mensajes visibles en Kafka UI (http://localhost:8081)

---

## ğŸ§ª Â¿CÃ³mo probar el sistema?

### **Paso 1: Arrancar la infraestructura**
```bash
cd platform/
docker-compose up --build -d
docker ps  # Verificar que todos los contenedores estÃ©n UP
```

### **Paso 2: Enviar evento de prueba**
**MÃ©todo 1: Con Postman/Insomnia**
- URL: `POST http://localhost:8080/events`
- Headers: `Content-Type: application/json`
- Body: JSON canÃ³nico (ver ejemplo arriba)

**MÃ©todo 2: Con curl**
```bash
curl -X POST http://localhost:8080/events \
  -H "Content-Type: application/json" \
  -d '{
    "event_version": "1.0",
    "event_type": "panic.button",
    "event_id": "123e4567-e89b-12d3-a456-426614174000",
    "producer": "artillery",
    "source": "simulated",
    "timestamp": "2025-09-04T21:00:00Z",
    "partition_key": "zone_4",
    "geo": { "zone": "zone_4", "lat": 14.62, "lon": -90.52 },
    "severity": "critical",
    "payload": {
      "tipo_de_alerta": "panico",
      "identificador_dispositivo": "BTN-001",
      "user_context": "movil"
    }
  }'
```

### **Paso 3: Verificar en Kafka UI**
- Abrir: http://localhost:8081
- Ir a Topics â†’ `t01.events.standardized`
- Verificar que el mensaje aparezca con la key `zone_4`

### **Respuestas esperadas:**
- âœ… `202 Accepted`: Evento procesado y publicado exitosamente
- âŒ `400 Bad Request`: Error de validaciÃ³n (JSON mal formado o campos faltantes)
- âŒ `500 Internal Server Error`: Error interno del microservicio

---

## ğŸ”§ Detalles tÃ©cnicos de implementaciÃ³n

### **Estructura del proyecto:**
```
src/ingestor/
â”œâ”€â”€ src/main/java/com/ciudadesinteligentes/ingestor/
â”‚   â”œâ”€â”€ IngestorApplication.java           # Main Spring Boot
â”‚   â”œâ”€â”€ controller/EventController.java    # REST API endpoints
â”‚   â”œâ”€â”€ service/EventService.java          # LÃ³gica de negocio
â”‚   â”œâ”€â”€ model/CanonicalEvent.java         # Modelo con @JsonProperty
â”‚   â”œâ”€â”€ config/KafkaConfig.java           # Auto-creaciÃ³n de topics
â”‚   â””â”€â”€ util/CanonicalEventValidator.java # Validador JSON Schema
â””â”€â”€ src/main/resources/
    â”œâ”€â”€ application.properties             # ConfiguraciÃ³n Spring
    â””â”€â”€ canonical-event-schema.json        # Esquema oficial v1.0
```

### **Configuraciones clave:**

**application.properties:**
```properties
spring.application.name=ingestor
spring.kafka.bootstrap-servers=kafka:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.admin.auto-create=true
app.kafka.topic.events-standardized=t01.events.standardized
```

**Auto-creaciÃ³n de topics (KafkaConfig.java):**
```java
@Bean
public NewTopic eventsStandardizedTopic() {
    return TopicBuilder.name("t01.events.standardized")
            .partitions(3)
            .replicas(1)
            .build();
}
```

**Mapeo snake_case â†” camelCase:**
```java
@JsonProperty("event_id")
private String eventId;

@JsonProperty("event_type") 
private String eventType;
// ... etc
```

---

## ğŸš€ Siguientes pasos (Roadmap)

### **Fase 2: Correlator + Redis (Siguiente prioridad)**
- **Objetivo**: Consumir eventos de Kafka y generar alertas correlacionadas
- **Funcionalidad**: 
  - Stream processor que correlaciona eventos dentro de ventanas de tiempo
  - Reglas inteligentes (ej: panic.button + velocidad alta = posible robo)
  - Cache en Redis para estado transitorio
  - PublicaciÃ³n de alertas en `t01.correlated.alerts`

### **Fase 3: Persistencia y ETL**
- Guardar eventos y alertas en PostgreSQL para anÃ¡lisis histÃ³rico
- ETL batch/streaming desde Kafka a base de datos
- Ãndices optimizados para consultas geoespaciales y temporales

### **Fase 4: Observabilidad y Dashboards**
- IntegraciÃ³n con Prometheus + Grafana
- MÃ©tricas de rendimiento de microservicios y Kafka
- Dashboards en tiempo real con heatmaps y timelines geoespaciales

### **Fase 5: Simuladores y carga**
- Artillery/JMeter para simulaciÃ³n de eventos masivos
- Generadores Python para diferentes tipos de sensores
- Pruebas de stress y benchmarking

### **Fase 6: Escalabilidad**
- Schema Registry para evoluciÃ³n de schemas
- Particionado inteligente por zona geogrÃ¡fica
- Auto-scaling de microservicios segÃºn carga

---

## ğŸ” Troubleshooting y comandos Ãºtiles

### **Ver logs del microservicio:**
```bash
docker logs platform_ingestor_1 --tail 50 -f
```

### **Verificar topics creados:**
```bash
docker exec -it platform_kafka_1 kafka-topics.sh --bootstrap-server localhost:9092 --list
```

### **Consumir mensajes directamente:**
```bash
docker exec -it platform_kafka_1 kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic t01.events.standardized \
  --from-beginning
```

### **Estado de contenedores:**
```bash
docker ps
docker-compose logs ingestor  # Solo logs del ingestor
```

### **Reiniciar solo el ingestor:**
```bash
docker-compose restart ingestor
# O con rebuild para cambios de cÃ³digo:
docker-compose up --build -d ingestor
```

---

## ğŸ’¡ Lecciones aprendidas y mejores prÃ¡cticas

1. **ValidaciÃ³n estricta**: El JSON Schema 2020-12 es fundamental para garantizar consistencia
2. **Auto-creaciÃ³n de topics**: Evita pasos manuales y mejora la experiencia de desarrollo
3. **Mapeo explÃ­cito**: `@JsonProperty` es mÃ¡s confiable que configuraciÃ³n global de Jackson
4. **Enriquecimiento automÃ¡tico**: Genera automÃ¡ticamente campos como `trace_id` si faltan
5. **Monitoreo visual**: Kafka UI es esencial para debugging y verificaciÃ³n
6. **DockerizaciÃ³n completa**: La infraestructura dockerizada facilita desarrollo y despliegue
7. **Logs estructurados**: Importantes para debugging en entornos distribuidos

---

## ğŸ“š Referencias tÃ©cnicas
- **JSON Schema oficial**: `src/ingestor/src/main/resources/canonical-event-schema.json`
- **Docker Compose**: `platform/docker-compose.yml`
- **Spring Kafka**: https://spring.io/projects/spring-kafka
---

**âœ… Estado**: Fase 1 completamente implementada y funcional  
**ğŸ¯ PrÃ³ximo objetivo**: Implementar Correlator para generar alertas inteligentes  
**ğŸ‘¥ Equipo**: Listo para demo y continuaciÃ³n del desarrollo

**Â¡Listo para avanzar a la siguiente fase!**
